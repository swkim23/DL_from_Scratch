\documentclass[12pt]{article}

\include{defs}

%%%%%%%%%%%%%%%
% Title Page
\title{ccOS Lifecycle}
\author{Infotainment Software Development Team \newline Hyundai Motor Company \newline }
\date{\today}
%%%%%%%%%%%%%%%

\begin{document}
	\maketitle
	
	\tableofcontents
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	% 본문의 시작 
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\clearpage
	\section{서론}
	
	편향(bias)는 뉴런이 얼마나 쉽게 활성화 되는지를 제어한다.
	가중치는 각 신호의 영향력을 의미한다.
	
	\subsection{목적}
	
	\begin{figure}[!h] %신경망 예시 그림
		\centering
		\includegraphics[width=0.8\textwidth]{fig/fig-3-1.png}
		\caption{신경망의 예}
	\end{figure}
	
	
	Perceptron은 복잡한 함수도 표현이 가능하다. 심지어 다층 퍼셉트론은 컴퓨터도 표현 가능하다.
	하지만, 퍼셉트론의 가중치를 설정하는 것은 여전히 사람에 의해서만 가능하다.
	
	신경망은 데이터로 부터 퍼셉트론의 가중치 설정을 자동으로 한다.
	
	\clearpage
	\section{신경망}
	입력층, 은닉층, 출력층 으로 구성
	활성화 함수 - 입력 신호의 총합을 출력 신호로 변환
	
	활성화 함수를 계단 함수에서 다른 함수로 변경하는 것이 신경망의 세계로 나아가는 열쇠이다.
	
	% $f(x)=\frac{1}{1+e^{-x}}$
	\[ f(x)=\frac{1}{1+\exp^(-x)}	\]
	
	신경망의 활성화 함수는 비선형 함수를 사용해야 한다. 여기서 비선형이란 하나의 직선으로 표현할 수 없는 함수를 의미한다.
	비선형 함수를 사용하는 이유는 선형 함수를 사용할 경우 신경망 층을 깊게 하면 의미가 사라지기 때문이다.
	
	신경망은 분류와 회귀에 이용할 수 있다. 이는 출력층의 활성화 함수의 선택을 결정 짓는 요인이 된다. 회귀에는 항등함수를 사용하고 분류에는 소프트맥스함수를 사용한다.
	
	\subsection{소프트맥스 함수의 특징}
	소프트맥스 함수의 출력은 0과 1.0사이의 실수이며, 함수 출력 총합은 1이다.
	이러한 성질을 이용하면 소프트맥스 함수의 출력을 확률로 생각할 수 있다.
	\[ f(v) = \frac{\exp(a_{k})} {\sum_{i=1}^{n}  {\exp(a_{i})}} \]
	
	소프트맥스 함수는 단조 증가 함수이기 때문에 소프트맥스 함수를 활성함수로 적용해도 각 원소의 대소 관계는 변화가 없다. 따라서, 신경망을 이용하여 분류를 할때 출력층의 소프트맥스 함수를 생략할 수 있다.
	
	\subsection{궁금한점}
	하지만, 분류에 소프트맥스 함수를 생략 할 수 있다면 결국 항등 함수와 무엇이 다른가?
	\clearpage
	
\section{신경망 학습}
학습이한 데이터로 부터 가중치 매개변수의 최적값을 자동으로 획득한다.
신경망이 학습을 위한 지표는 손실 함수를 사용한다.

\end{document}          
